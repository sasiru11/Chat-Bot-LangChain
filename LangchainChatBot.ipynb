{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOiLPVwgIDplGGicnBK1YTo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sasiru11/Chat-Bot-LangChain/blob/main/LangchainChatBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "MVAcZKA3iuXW"
      },
      "outputs": [],
      "source": [
        "#Install necessory packages\n",
        "!pip install langchain -qU"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-openai -qU"
      ],
      "metadata": {
        "id": "oWy5rf5yi8Cg"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Install necessory librabies\n",
        "import os\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "Q_gHClohjEdl"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize OpenAI LLM"
      ],
      "metadata": {
        "id": "KIrp4rdYjwie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "#Set OpenAI API Key\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] =userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "#Initialize the ChatOpenAI model\n",
        "\n",
        "llm= ChatOpenAI(model_name='gpt-3.5-turbo',\n",
        "temperature=0\n",
        "                )"
      ],
      "metadata": {
        "id": "h5GxzD0ljXzn"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize Promt Template"
      ],
      "metadata": {
        "id": "VviSNkRuk-7P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "#Create a prompt template\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "      (\"system\",\"You are an intelligent chat bot, answer the following question\"),\n",
        "      (\"user\",\"{question}\")\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "jB5vmsSDk25N"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initilize Output Praser"
      ],
      "metadata": {
        "id": "G4f_Hnjal_Dm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "#Initialize the string output parser\n",
        "\n",
        "parser = StrOutputParser()"
      ],
      "metadata": {
        "id": "WZ2nztWtlrIW"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make The Chain"
      ],
      "metadata": {
        "id": "UBUg-vYTmqY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Chain the prompt, LLM , and output parser\n",
        "\n",
        "chain = prompt | llm |parser"
      ],
      "metadata": {
        "id": "c5orP5q9mgDO"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What is generative AI\"\n",
        "response = chain.invoke({\"question\":question})\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-W-mE6hm690",
        "outputId": "6154f8e8-2d66-43a1-8de7-7ffa6df73357"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generative AI refers to artificial intelligence systems that are capable of creating new content, such as images, text, or music, based on patterns and data they have been trained on. These systems use algorithms to generate new content that is similar to the input data they have been provided with. Generative AI has applications in various fields, including art, design, and content creation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize Prompt Templae for Dynamic Interaction"
      ],
      "metadata": {
        "id": "sfirSjwB52A_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import MessagesPlaceholder\n",
        "from langchain_core.messages import HumanMessage, AIMessage ,SystemMessage\n",
        "\n",
        "#Create a prompt Template using messagesPlaceholder for the question\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        SystemMessage(content = \"You are a inteligent chatbot, answer the following questions\"),\n",
        "        MessagesPlaceholder(variable_name=\"question\")\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "scJmOz_fnKUi"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Chain the prompt, LLM and output parser\n",
        "\n",
        "chain = prompt |llm |parser\n",
        "\n",
        "question = \"My name is Sasiru Nishamal\"\n",
        "response = chain.invoke({\"question\":[HumanMessage(content=question)]})\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pHfxFHt8coj",
        "outputId": "afa0e223-f5e8-4f15-85ba-0372d446c85a"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello Sasiru Nishamal! How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Who am I?\"\n",
        "response = chain.invoke({\"question\":[HumanMessage(content=question)]})\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZWrd2JY9GX5",
        "outputId": "4301f69c-b793-41f8-9173-c3aa2100060f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm sorry, but I am unable to determine who you are as I do not have access to personal information. How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize Prompt Template with Predefined Conversation History"
      ],
      "metadata": {
        "id": "dO3B9Pw59Uuo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a prompte template with a predefined conversation history and a new question placeholder\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        SystemMessage(content=\"Yoy are an intelligent chat bot, answer the following wuestion\"),\n",
        "        HumanMessage(content=\"My name is Sasiru Nishamal\"),\n",
        "        AIMessage(content=\"Hi Sasiru Nishamal! How can I help you today?\"),\n",
        "        MessagesPlaceholder(variable_name=\"question\")\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "YqsedZsC9apB"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Chain prompt, LLM and parser\n",
        "\n",
        "chain = prompt |llm |parser\n",
        "\n",
        "question = \"Who am I?\"\n",
        "response = chain.invoke({\"question\":[HumanMessage(content=question)]})\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHs4MaLa-HqJ",
        "outputId": "c821860e-bec1-4d20-cc4e-4b150794e6cb"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are Sasiru Nishamal, the person who introduced themselves to me earlier. How can I assist you further?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initilize Prompt Template to handle Dynamic conversation History"
      ],
      "metadata": {
        "id": "rdn7dCOa-WZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        SystemMessage(content=\"You are an intelligent chatbot, Answer the following question\"),\n",
        "        MessagesPlaceholder(variable_name=\"history\"),\n",
        "        MessagesPlaceholder(variable_name=\"question\")\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "TThHPSzy-cus"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the history\n",
        "\n",
        "history = [\n",
        "    HumanMessage(content = \"My name is sasiru Nishamal\"),\n",
        "    AIMessage(content = \"Nice to meet you Sasiru Nishamal\"),\n",
        "    HumanMessage(content = \"What is 2 + 2 ?\"),\n",
        "    AIMessage(content = \"4\")\n",
        "]"
      ],
      "metadata": {
        "id": "ZDTsQdZv-6K3"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chain the Prompt, LLM, Parser\n",
        "\n",
        "chain = prompt |llm |parser"
      ],
      "metadata": {
        "id": "AV-zmoih_eHN"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Who am I ?\"\n",
        "response = chain.invoke({\"history\": history,\"question\":[HumanMessage(content=question)]})\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTTkGj4x_pIf",
        "outputId": "58d242c5-7a6f-48a0-a637-ec492d89cdf7"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are Sasiru Nishamal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Update the Display Conversation history"
      ],
      "metadata": {
        "id": "a3jSxc4aAGpS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extent the history with the latest question and response\n",
        "history.extend([HumanMessage(content=question),AIMessage(content=response)])\n",
        "\n",
        "question = \"Whai is my last question\"\n",
        "response = chain.invoke({\"history\": history,\"question\":[HumanMessage(content=question)]})\n",
        "history.extend([HumanMessage(content=question),AIMessage(content=response)])\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_snOfqniAJrz",
        "outputId": "2377a47f-ac4f-49e7-8f96-8281a62ecdcb"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your last question was \"Whai is my last question\"\n"
          ]
        }
      ]
    }
  ]
}